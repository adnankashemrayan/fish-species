import streamlit as st
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
from torchvision import transforms
from PIL import Image
import base64
import os

# ==================================================
# PAGE CONFIG
# ==================================================
st.set_page_config(
    page_title="Fish Species Detection",
    page_icon="üêü",
    layout="centered",
    initial_sidebar_state="collapsed"
)

# ==================================================
# GLOBAL STYLES
# ==================================================
def inject_css(image_path=""):
    try:
        with open(image_path, "rb") as f:
            encoded = base64.b64encode(f.read()).decode()
        bg_css = f"""
        background:
          linear-gradient(rgba(0,0,0,0.72), rgba(0,0,0,0.72)),
          url("data:image/png;base64,{encoded}");
        """
    except:
        bg_css = "background: linear-gradient(135deg, #0f2027, #203a43, #2c5364);"

    st.markdown(f"""
    <style>
    html, body {{ font-family: 'Inter', sans-serif; }}
    .stApp {{ {bg_css} background-size: cover; background-position: center; background-attachment: fixed; }}
    .block-container {{ max-width: 800px; background: rgba(255,255,255,0.12); backdrop-filter: blur(24px); padding: 3.6rem; border-radius: 28px; border: 1px solid rgba(255,255,255,0.25); box-shadow: 0 35px 100px rgba(0,0,0,0.65); }}
    button {{ width: 100%; height: 3.5em; border-radius: 18px !important; font-size: 18px !important; font-weight: 600; background: linear-gradient(135deg,#00c6ff,#0072ff); color: white !important; border: none; }}
    button:hover {{ transform: scale(1.03); transition: 0.25s ease; }}
    section[data-testid="stFileUploader"] {{ background: rgba(0,0,0,0.45); border-radius: 18px; padding: 22px; border: 1px dashed rgba(255,255,255,0.45); }}
    .stProgress > div > div {{ background-image: linear-gradient(90deg,#00c6ff,#0072ff); }}
    </style>""", unsafe_allow_html=True)

inject_css("assets/watermark.png")

# ==================================================
# SIDEBAR
# ==================================================
with st.sidebar:
    st.markdown("## üêü Fish AI Platform")
    language = st.selectbox("üåê Language", ["English", "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ"])
    enable_explain = st.checkbox("üî¨ Enable Explainability (Grad-CAM)", False)
    enable_report = st.checkbox("üìÑ Enable PDF Report", False)
    st.markdown("""
    ---
    **Model**
    - SimCLR Encoder
    - Linear Classifier
    - Self-Supervised Features
    """)

# ==================================================
# TEXT
# ==================================================
TEXT = {
    "English": {
        "title": "Fish Species Detection",
        "subtitle": "Industry-Grade AI Fish Classification Platform",
        "upload": "üì§ Upload a fish image",
        "analyze": "üîç Analyze Image",
        "results": "Prediction Results"
    },
    "‡¶¨‡¶æ‡¶Ç‡¶≤‡¶æ": {
        "title": "‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶™‡ßç‡¶∞‡¶ú‡¶æ‡¶§‡¶ø ‡¶∂‡¶®‡¶æ‡¶ï‡ßç‡¶§‡¶ï‡¶∞‡¶£",
        "subtitle": "‡¶á‡¶®‡ßç‡¶°‡¶æ‡¶∏‡ßç‡¶ü‡ßç‡¶∞‡¶ø-‡¶ó‡ßç‡¶∞‡ßá‡¶° AI ‡¶´‡¶ø‡¶∂ ‡¶ï‡ßç‡¶≤‡¶æ‡¶∏‡¶ø‡¶´‡¶ø‡¶ï‡ßá‡¶∂‡¶® ‡¶∏‡¶ø‡¶∏‡ßç‡¶ü‡ßá‡¶Æ",
        "upload": "üì§ ‡¶Æ‡¶æ‡¶õ‡ßá‡¶∞ ‡¶õ‡¶¨‡¶ø ‡¶Ü‡¶™‡¶≤‡ßã‡¶° ‡¶ï‡¶∞‡ßÅ‡¶®",
        "analyze": "üîç ‡¶õ‡¶¨‡¶ø ‡¶¨‡¶ø‡¶∂‡ßç‡¶≤‡ßá‡¶∑‡¶£ ‡¶ï‡¶∞‡ßÅ‡¶®",
        "results": "‡¶™‡ßÇ‡¶∞‡ßç‡¶¨‡¶æ‡¶≠‡¶æ‡¶∏‡ßá‡¶∞ ‡¶´‡¶≤‡¶æ‡¶´‡¶≤"
    }
}
T = TEXT[language]

# ==================================================
# DEVICE
# ==================================================
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# ==================================================
# CLASS NAMES
# ==================================================
CLASS_NAMES = [
    "Baim","Bata","Batasio(Tenra)","Chitul","Croaker(Poya)",
    "Hilsha","Kajoli","Meni","Pabda","Poli","Puti",
    "Rita","Rui","Rupchada","Silver Carp","Telapiya",
    "Carp","K","Kaikka","Koral","Shrimp"
]

# ==================================================
# SIMCLR ENCODER
# ==================================================
class SimCLR(nn.Module):
    def __init__(self):
        super().__init__()
        self.encoder = torchvision.models.resnet50(weights=None)
        self.encoder.fc = nn.Identity()
        self.projector = nn.Sequential(
            nn.Linear(2048, 512),
            nn.ReLU(),
            nn.Linear(512, 128)
        )

    def forward(self, x):
        h = self.encoder(x)
        z = self.projector(h)
        return F.normalize(z, dim=1)

# ==================================================
# LOAD MODELS
# ==================================================
@st.cache_resource(show_spinner=False)
def load_models():
    BASE_DIR = os.path.dirname(__file__)
    encoder_path = os.path.join(BASE_DIR, "models", "fish_simclr_encoder.pt")
    classifier_path = os.path.join(BASE_DIR, "models", "fish_final_model.pt")

    if not os.path.exists(encoder_path) or not os.path.exists(classifier_path):
        st.error("‚ùå Model files missing! Please add them to 'models/' folder.")
        st.stop()

    # --- Encoder
    encoder_model = SimCLR()
    state = torch.load(encoder_path, map_location=DEVICE)
    encoder_model.encoder.load_state_dict(state, strict=False)
    encoder_model.eval().to(DEVICE)

    # --- Classifier
    cls_state = torch.load(classifier_path, map_location=DEVICE)
    classifier = nn.Linear(2048, len(CLASS_NAMES)).to(DEVICE)
    classifier.load_state_dict(cls_state, strict=False)
    classifier.eval()

    # --- Warm-up
    with torch.no_grad():
        dummy = torch.randn(1,3,224,224).to(DEVICE)
        feat = encoder_model.encoder(dummy).view(1,-1)
        _ = classifier(feat)

    return encoder_model, classifier

encoder_model, classifier = load_models()

# ==================================================
# TRANSFORMS
# ==================================================
transform = transforms.Compose([
    transforms.Resize((224,224)),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])
])

# ==================================================
# PREDICTION
# ==================================================
def predict_topk(img, k=3):
    img_tensor = transform(img).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        feat = encoder_model.encoder(img_tensor).view(1,-1)
        probs = torch.softmax(classifier(feat), dim=1)[0]
    topk = torch.topk(probs, k)
    return [(CLASS_NAMES[i], float(topk.values[idx]*100)) for idx,i in enumerate(topk.indices)]

# ==================================================
# HEADER
# ==================================================
st.markdown(f"""
<div style="text-align:center;">
    <h1 style="font-size:48px;">üêü {T['title']}</h1>
    <p style="font-size:18px; color:#dddddd;">{T['subtitle']}</p>
</div>
<hr style="margin:32px 0;">
""", unsafe_allow_html=True)

# ==================================================
# MAIN APP
# ==================================================
file = st.file_uploader(T["upload"], type=["jpg","jpeg","png"])

if file:
    try:
        image = Image.open(file).convert("RGB")
        st.image(image, caption="Uploaded Image", use_column_width=True)

        if st.button(T["analyze"]):
            with st.spinner("Running analysis..."):
                results = predict_topk(image)

            st.markdown(f"## üß† {T['results']}")
            for label, conf in results:
                st.markdown(f"**{label}**")
                st.progress(int(conf))
                st.caption(f"Confidence: {conf:.2f}%")

            if enable_explain:
                st.info("üî¨ Grad-CAM enabled (hook ready).")
            if enable_report:
                st.info("üìÑ PDF report enabled (hook ready).")

    except Exception as e:
        st.error(f"‚ùå Error: {str(e)}")

# ==================================================
# FOOTER
# ==================================================
st.markdown("""
<hr style="margin-top:50px;">
<p style="text-align:center; color:#cfcfcf; font-size:14px;">
¬© 2026 ¬∑ Fish AI Classification Platform<br>
Built with PyTorch ¬∑ SimCLR ¬∑ Streamlit<br>
Developed by <b>Riad</b>
</p>
""", unsafe_allow_html=True)
